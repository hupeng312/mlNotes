{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = datasets.load_boston()\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "\n",
    "X = X[y < 50]\n",
    "y = y[y < 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from playML.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.05 ms, sys: 1.33 ms, total: 2.37 ms\n",
      "Wall time: 1.27 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.78963690744563542"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from playML.LinearRegression import LinearRegression\n",
    "\n",
    "lin_reg1 = LinearRegression()\n",
    "%time lin_reg1.fit_normal(X_train, y_train)\n",
    "lin_reg1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用梯度下降法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hupeng/mlNotes/06gradient_descent/playML/LinearRegression.py:32: RuntimeWarning: overflow encountered in square\n",
      "  return np.sum((y - X_b.dot(theta)) ** 2) / len(y)\n",
      "/home/hupeng/mlNotes/06gradient_descent/playML/LinearRegression.py:48: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if (abs(J(theta, X_b, y) - J(last_theta, X_b, y)) < epsilon):\n",
      "/home/hupeng/mlNotes/06gradient_descent/playML/LinearRegression.py:37: RuntimeWarning: overflow encountered in multiply\n",
      "  return X_b.T.dot(X_b.dot(theta) - y) * 2. / len(y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg2 = LinearRegression()\n",
    "lin_reg2.fit_gd(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg2.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  8.19900000e-02,   0.00000000e+00,   1.39200000e+01,\n",
       "          0.00000000e+00,   4.37000000e-01,   6.00900000e+00,\n",
       "          4.23000000e+01,   5.50270000e+00,   4.00000000e+00,\n",
       "          2.89000000e+02,   1.60000000e+01,   3.96900000e+02,\n",
       "          1.04000000e+01],\n",
       "       [  9.06500000e-02,   2.00000000e+01,   6.96000000e+00,\n",
       "          1.00000000e+00,   4.64000000e-01,   5.92000000e+00,\n",
       "          6.15000000e+01,   3.91750000e+00,   3.00000000e+00,\n",
       "          2.23000000e+02,   1.86000000e+01,   3.91340000e+02,\n",
       "          1.36500000e+01],\n",
       "       [  2.28760000e-01,   0.00000000e+00,   8.56000000e+00,\n",
       "          0.00000000e+00,   5.20000000e-01,   6.40500000e+00,\n",
       "          8.54000000e+01,   2.71470000e+00,   5.00000000e+00,\n",
       "          3.84000000e+02,   2.09000000e+01,   7.08000000e+01,\n",
       "          1.06300000e+01],\n",
       "       [  1.40520000e-01,   0.00000000e+00,   1.05900000e+01,\n",
       "          0.00000000e+00,   4.89000000e-01,   6.37500000e+00,\n",
       "          3.23000000e+01,   3.94540000e+00,   4.00000000e+00,\n",
       "          2.77000000e+02,   1.86000000e+01,   3.85810000e+02,\n",
       "          9.38000000e+00],\n",
       "       [  3.57800000e-02,   2.00000000e+01,   3.33000000e+00,\n",
       "          0.00000000e+00,   4.42900000e-01,   7.82000000e+00,\n",
       "          6.45000000e+01,   4.69470000e+00,   5.00000000e+00,\n",
       "          2.16000000e+02,   1.49000000e+01,   3.87310000e+02,\n",
       "          3.76000000e+00],\n",
       "       [  4.33700000e-02,   2.10000000e+01,   5.64000000e+00,\n",
       "          0.00000000e+00,   4.39000000e-01,   6.11500000e+00,\n",
       "          6.30000000e+01,   6.81470000e+00,   4.00000000e+00,\n",
       "          2.43000000e+02,   1.68000000e+01,   3.93970000e+02,\n",
       "          9.43000000e+00],\n",
       "       [  1.30751000e+01,   0.00000000e+00,   1.81000000e+01,\n",
       "          0.00000000e+00,   5.80000000e-01,   5.71300000e+00,\n",
       "          5.67000000e+01,   2.82370000e+00,   2.40000000e+01,\n",
       "          6.66000000e+02,   2.02000000e+01,   3.96900000e+02,\n",
       "          1.47600000e+01],\n",
       "       [  9.18702000e+00,   0.00000000e+00,   1.81000000e+01,\n",
       "          0.00000000e+00,   7.00000000e-01,   5.53600000e+00,\n",
       "          1.00000000e+02,   1.58040000e+00,   2.40000000e+01,\n",
       "          6.66000000e+02,   2.02000000e+01,   3.96900000e+02,\n",
       "          2.36000000e+01],\n",
       "       [  1.43900000e-02,   6.00000000e+01,   2.93000000e+00,\n",
       "          0.00000000e+00,   4.01000000e-01,   6.60400000e+00,\n",
       "          1.88000000e+01,   6.21960000e+00,   1.00000000e+00,\n",
       "          2.65000000e+02,   1.56000000e+01,   3.76700000e+02,\n",
       "          4.38000000e+00],\n",
       "       [  2.86558000e+01,   0.00000000e+00,   1.81000000e+01,\n",
       "          0.00000000e+00,   5.97000000e-01,   5.15500000e+00,\n",
       "          1.00000000e+02,   1.58940000e+00,   2.40000000e+01,\n",
       "          6.66000000e+02,   2.02000000e+01,   2.10970000e+02,\n",
       "          2.00800000e+01]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg2.fit_gd(X_train, y_train, eta=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3405779996846231"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%time lin_reg2.fit_gd(X_train, y_train, eta=0.000001, n_iters=1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3405779996846231"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 效果低, 因为数据大小不一样,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用梯度下降法前进行数据归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StandardScaler = StandardScaler()\n",
    "StandardScaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_standard = StandardScaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg3 = LinearRegression()\n",
    "lin_reg3.fit_gd(X_train_standard, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-14524.696107399097"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg3.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_standard = StandardScaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78962954631482773"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg3.score(X_test_standard, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 比较正规方程和梯度下降法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 5000) (1000,)\n"
     ]
    }
   ],
   "source": [
    "m = 1000\n",
    "n = 5000\n",
    "\n",
    "big_X = np.random.normal(size=(m,n))\n",
    "true_theta = np.random.uniform(0.0, 100.0, size=n+1)\n",
    "big_y = big_X.dot(true_theta[1:]) + true_theta[0] + np.random.normal(0, 10.0, size=m)\n",
    "X_train\n",
    "print(big_X.shape, big_y.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.8 s, sys: 921 ms, total: 27.7 s\n",
      "Wall time: 11.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_reg1 = LinearRegression()\n",
    "%time big_reg1.fit_normal(big_X, big_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.44 s, sys: 97.2 ms, total: 7.54 s\n",
      "Wall time: 4.15 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_reg2 = LinearRegression()\n",
    "%time big_reg2.fit_gd(big_X, big_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
